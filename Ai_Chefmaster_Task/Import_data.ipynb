{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support for structured, semi-structured, and unstructured data from diverse sources, including text, PDFs (typed and handwritten), and photographs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import openpyxl\n",
    "import xml.etree.ElementTree as ET\n",
    "import fitz\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Import Data from Structured Data( CSV, EXCEL)\n",
    "def import_data(path):\n",
    "#Structured Data\n",
    "    if path.endswith('.csv'):\n",
    "        data = pd.read_csv(path)\n",
    "        return data\n",
    "    \n",
    "    elif path.endswith('.xlsx'):\n",
    "        data = pd.read_excel(path)\n",
    "        return data\n",
    "    \n",
    "#Semi-structured Data\n",
    "    elif path.endswith('.json'):\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "        \n",
    "    elif path.endswith('.xml'):\n",
    "        tree = ET.parse(path)\n",
    "        root = tree.getroot()\n",
    "        return ET.tostring(root, encoding='utf-8').decode('utf-8')\n",
    "    \n",
    "#Unstructured Data\n",
    "    elif path.endswith('.txt'):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            return file.read()\n",
    "        \n",
    "    elif path.endswith('.pdf'):\n",
    "        doc = fitz.open(path)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            page_text = page.get_text(\"text\")\n",
    "            if page_text.strip():\n",
    "                text += page_text  \n",
    "            else:\n",
    "                img = Image.open(io.BytesIO(page.get_pixmap().tobytes(\"png\")))\n",
    "                text += pytesseract.image_to_string(img, lang='eng') \n",
    "        return text\n",
    "    \n",
    "    elif path.endswith(('.png', '.jpeg', 'jpg')):\n",
    "        image = Image.open(path) \n",
    "        text = pytesseract.image_to_string(image, lang='eng')\n",
    "        return text\n",
    "    \n",
    "    else:\n",
    "        return 'Unsupported file format'\n",
    "    \n",
    "data = import_data(r'C:\\Users\\vrind\\vrinda\\python\\Ai_Chefmaster_Task\\Data\\apple_77.jpg')\n",
    "#data.head(20)\n",
    "print(data)\n",
    "#print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OCR support for converting paper-based into digital formats, accommodating English, Hindi, Tamil, Bengali. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text: मनुष्वजात जन्मतःच स्वतंत्र आई व सवजणांना समान प्राते\n",
      "[न अधिकार Med, त्यांना विचारदाक्ती व सदसद्धिविकवुद्दी 2\n",
      ": লন স্বোলী கண்களி வளன்‌ आचरण கர்‌.\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Convert image to grayscale and apply thresholding to enhance OCR accuracy.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)  \n",
    "    return binary\n",
    "\n",
    "def extract_data(path, lang=\"eng+hin+ben+tam\"):\n",
    "    if path.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image = preprocess_image(path)\n",
    "        text = pytesseract.image_to_string(image, lang=lang, config=\"--psm 6\") \n",
    "        return text.strip()\n",
    "    else:\n",
    "        return \"Unsupported file format\"\n",
    "\n",
    "data2 = extract_data(r'C:\\Users\\vrind\\vrinda\\python\\Ai_Chefmaster_Task\\Data\\Mar.jpg', lang=\"eng+hin+ben+tam\")\n",
    "print(\"Extracted Text:\", data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मनुष्यजात जन्मतःच स्वतंत्र आह व सवजणांना समान प्रति!\n",
      "[न अधिकार আইল. त्यांना विचारदाक्ती व सदसद्धिवेकवुद्दी ल\n",
      ": নল সোল एकमेकांशी வ்ளன भावनेने आचरण கர்‌.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text(path, lang=\"eng+hin+tam+ben\"):\n",
    "    image = Image.open(path)\n",
    "    text = pytesseract.image_to_string(image, lang=lang)\n",
    "    return text\n",
    "\n",
    "data = extract_text(r\"C:\\Users\\vrind\\vrinda\\python\\Ai_Chefmaster_Task\\Data\\Mar.jpg\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'food_management_data.csv' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Issue Type\": [\n",
    "        \"Spoiled Ingredients\",\n",
    "        \"Overproduction\",\n",
    "        \"Storage Issues\",\n",
    "        \"Supply Chain Delays\",\n",
    "        \"High Food Wastage\",\n",
    "        \"Staff Mismanagement\",\n",
    "        \"Poor Inventory Tracking\"\n",
    "    ],\n",
    "    \"Occurrences\": [23, 15, 10, 8, 30, 12, 20]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "csv_filename = \"food_management_data.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"CSV file '{csv_filename}' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Common Issues in Food Management:\n",
      "  Issue Reported  Count\n",
      "0  Expired Stock      1\n",
      "1       Spoilage      1\n",
      "2        Bruised      1\n",
      "\n",
      "Most Common Root Causes:\n",
      "          Root Cause  Count\n",
      "0         Late Usage      1\n",
      "1  Improper Freezing      1\n",
      "2     Rough Handling      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "file_path = r\"C:\\Users\\vrind\\vrinda\\python\\Ai_Chefmaster_Task\\Data\\food_management.csv\"  # Update with your actual file path\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Summarize the most common issues and root causes\n",
    "issue_counts = df['Issue Reported'].value_counts().reset_index()\n",
    "issue_counts.columns = ['Issue Reported', 'Count']\n",
    "\n",
    "root_cause_counts = df['Root Cause'].value_counts().reset_index()\n",
    "root_cause_counts.columns = ['Root Cause', 'Count']\n",
    "\n",
    "print(\"\\nMost Common Issues in Food Management:\")\n",
    "print(issue_counts.head())\n",
    "\n",
    "print(\"\\nMost Common Root Causes:\")\n",
    "print(root_cause_counts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c036876fc64ce4a5b653338981c7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vrind\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vrind\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2eb854c494453eb0074429e5f5d0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a909bb94f4e44e4fb19b00923a5ad2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01df8bc028f4ecb90d4096c1bbc6ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d147396824c41c2be114c393fb892b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27708eefc3124da08ed57bdc26f0967d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the common problems in food management?\n",
      "\n",
      "The most likely reason for these common problems is that you have to prepare a whole lot more vegetables. That is also why you must eat a lot more vegetables. There are many vegetables in the food pantry that are high in fiber and nutrients, yet they are low in many nutritional quality (e.g., carrots, celery) and cannot be cooked properly (rice). Some other vegetables such as bell peppers (Chocos friti\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "response = generator(\"What are the common problems in food management?\", max_length=100)\n",
    "print(response[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify the root causes of food management issues in the supply chain and storage.\n",
      "\n",
      "What is the most important point of the food supply chain?\n",
      "\n",
      "The food supply chain is an important part of a supply chain that is used by the food producers and their workers to produce food for their employees and customers. The food production process is the main part of the food supply chain. It is important to understand the key factors that affect the food production process.\n",
      "\n",
      "How are the food production processes performed?\n",
      "\n",
      "The food production process is the process of preparing food and processing it into products and products. The food production process is mainly used by the production of food products. It is also used for the production of other products, such as raw\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"  # A better model for text generation\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token  \n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"Identify the root causes of food management issues in the supply chain and storage.\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Generate output with correct sampling\n",
    "output = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    max_length=150,  \n",
    "    num_return_sequences=1,  \n",
    "    temperature=0.7,  # Increase randomness\n",
    "    top_k=50,  # Reduce repetition\n",
    "    top_p=0.9,  # Diverse responses\n",
    "    repetition_penalty=1.2,  \n",
    "    do_sample=True  # ENABLE SAMPLING!\n",
    ")\n",
    "\n",
    "# Decode and print output\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform a Root Cause Analysis (RCA) on food management issues in the supply chain and storage. \n",
      "Identify common failure points and their underlying causes. \n",
      "\n",
      "Key areas to analyze:\n",
      "- Inventory mismanagement\n",
      "- Storage conditions (temperature, humidity)\n",
      "- Supply chain disruptions\n",
      "- Quality control failures\n",
      "- Food spoilage and waste\n",
      "- Logistics and transportation delays\n",
      "\n",
      "Learn more about this project at http://www/rblc3.org\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"gpt2\"  # More robust than GPT-2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token  \n",
    "\n",
    "# Define a more detailed prompt for RCA\n",
    "prompt = \"\"\"Perform a Root Cause Analysis (RCA) on food management issues in the supply chain and storage. \n",
    "Identify common failure points and their underlying causes. \n",
    "\n",
    "Key areas to analyze:\n",
    "- Inventory mismanagement\n",
    "- Storage conditions (temperature, humidity)\n",
    "- Supply chain disruptions\n",
    "- Quality control failures\n",
    "- Food spoilage and waste\n",
    "- Logistics and transportation delays\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Generate response with better sampling control\n",
    "output = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    max_length=200,  \n",
    "    num_return_sequences=1,  \n",
    "    temperature=0.7,  # Add randomness\n",
    "    top_k=50,  # Reduce generic outputs\n",
    "    top_p=0.9,  # Diverse responses\n",
    "    repetition_penalty=1.2,  \n",
    "    do_sample=True  # ENABLE SAMPLING\n",
    ")\n",
    "\n",
    "# Decode and print output\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
